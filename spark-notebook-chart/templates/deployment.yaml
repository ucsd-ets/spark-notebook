# ConfigMap for /etc/passwd
apiVersion: v1
kind: ConfigMap
metadata:
  name: passwd
data:
  spark-defaults.conf: |
    spark.master spark://spark-master:7077
    spark.driver.extraLibraryPath /opt/hadoop/lib/native
    spark.app.id KubernetesSpark
    spark.driver.port 20002
    spark.executor.port 40002
    spark.blockManager.port 50002
    spark.fileserver.port 60002
    spark.broadcast.port 60003
    spark.replClassServer.port 60004
    spark.port.maxRetries 1
  passwd: |
    bin:x:2:2:bin:/bin:/usr/sbin/nologin
    sys:x:3:3:sys:/dev:/usr/sbin/nologin
    sync:x:4:65534:sync:/bin:/bin/sync
    games:x:5:60:games:/usr/games:/usr/sbin/nologin
    man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
    lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
    mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
    news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
    uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
    proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
    www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
    backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
    list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
    irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
    gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
    nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
    systemd-timesync:x:100:102:systemd Time Synchronization,,,:/run/systemd:/bin/false
    systemd-network:x:101:103:systemd Network Management,,,:/run/systemd/netif:/bin/false
    systemd-resolve:x:102:104:systemd Resolver,,,:/run/systemd/resolve:/bin/false
    systemd-bus-proxy:x:103:105:systemd Bus Proxy,,,:/run/systemd:/bin/false
    _apt:x:104:65534::/nonexistent:/bin/false
    messagebus:x:105:107::/var/run/dbus:/bin/false
    spark:x:1000:1000::/home/spark:
    {{ .Values.username }}:{{ .Values.uid }}:{{ .Values.username }}::/home/{{ .Values.username}}
---
### Definition for spark workers ###
apiVersion: apps/v1
kind: Deployment
metadata:
  name: worker
  labels:
    app: worker
    {{- include "spark-notebook-chart.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount | default 2}}
  selector:
    matchLabels:
      app: worker
      {{- include "spark-notebook-chart.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        app: worker
        {{- include "spark-notebook-chart.selectorLabels" . | nindent 8 }}
    spec:
      securityContext:
        runAsUser: {{ .Values.uid }}
      containers:
      - name: worker
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        env:
        - name: SPARK_USER
          value: {{ .Values.username }}
        - name: USER
          value: {{ .Values.username }}
        - name: SPARK_WORKER_PORT
          value: "20002"
        - name: LOGNAME
          value: {{ .Values.username }}
        # command: ["/bin/sh","-c"]
        args: [
              "/bin/sh",
              "-c",
              "unset SPARK_MASTER_PORT; /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 --webui-port 8081 --cores 2 --memory 8G"
        ]
        resources:
          requests:
            memory: "8Gi"
            cpu: "2000m"
          limits:
            memory: "8Gi"
            cpu: "2000m"
        ports: 
        {{- range .Values.workers.ports}}
        - containerPort: {{ .portNumber }}
        {{- end }} 
        volumeMounts:
          - mountPath: /etc/passwd
            subPath: passwd
            name: config-volume
          - mountPath: /home/{{ .Values.username }}
            name: home
          - mountPath: /opt/spark/conf/spark-defaults.conf
            name: config-volume
            subPath: spark-defaults.conf
      volumes:
        - name: home
          persistentVolumeClaim:
            claimName: home
        - name: config-volume
          configMap:
            name: passwd
            defaultMode: 0777
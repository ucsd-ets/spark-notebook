# 1 master pod, 1 worker

# goal is to figure out how to get spark to run as master in the master pod and get spark to run as worker on worker pod and have them network together


### Definition for spark master and its service ###
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-main
  labels:
    app: spark-main
spec:
  replicas: 1
  selector:
    matchLabels:
      run: spark-main
  template:
    metadata:
      labels:
        run: spark-main
    spec:
      containers:
      - name: spark-main
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        command: ["/bin/sh","-c"]
        args: ["./spark-3.3.0-bin-hadoop3/sbin/start-master.sh; sleep inf"]
        ports:
        - containerPort: 7077
        - containerPort: 8080
        - containerPort: 4040
        - containerPort: 20002
        - containerPort: 50002
        - containerPort: 60002
        - containerPort: 60003
        - containerPort: 60004
---
apiVersion: v1
kind: Service
metadata:
  name: spark-main
  labels: 
    run: spark-main
spec:
  ports:
    - name: webui
      port: 8080
      targetPort: 8080
    - name: spark
      port: 7077
      targetPort: 7077
    - name: sparkui
      port: 4040
      targetPort: 4040
    - name: driverport
      port: 20002
      targetPort: 20002
    - name: blockmgrport
      port: 50002
      targetPort: 50002
    - name: fileserverport
      port: 60002
      targetPort: 60002
    - name: broadcastport
      port: 60003
      targetPort: 60003
    - name: replicaport
      port: 60004
      targetPort: 60004
  selector:
    run: spark-main
---
### Definition for spark worker and its service ###
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-dev
  labels:
    app: spark-dev
spec:
  replicas: 2
  selector:
    matchLabels:
      run: spark-dev
  template:
    metadata:
      labels:
        run: spark-dev
    spec:
      containers:
      - name: spark-dev
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        command: ["/bin/sh","-c"]
        args: ["./spark-3.3.0-bin-hadoop3/sbin/start-worker.sh spark://spark-main:7077; sleep inf"]
        ports:
        - containerPort: 8081
        - containerPort: 30002
        - containerPort: 40002
        - containerPort: 50002
        - containerPort: 60002
        - containerPort: 60003
        - containerPort: 60004
      initContainers:
      - name: init-checker
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        imagePullPolicy: Always
        command: ["/opt/ping-check.sh"]
---
kind: Service
apiVersion: v1
metadata:
  name: spark-dev
  labels:
    # component: spark-dev
    run: spark-dev
spec:
  ports:
    - name: webui
      port: 8081
      targetPort: 8081
    - name: workerport
      port: 30002
      targetPort: 30002
    - name: executorport
      port: 40002
      targetPort: 40002
    - name: blockmgr
      port: 50002
      targetPort: 50002
    - name: fileserverport
      port: 60002
      targetPort: 60002
    - name: broadcastport
      port: 60003
      targetPort: 60003
    - name: replicaport
      port: 60004
      targetPort: 60004
  selector:
    run: spark-dev
---
### Definition for spark jupyter worker and its service ###
apiVersion: v1
kind: Pod
metadata:
  name: spark-jupyter
  labels:
    app: spark-jupyter
spec:
  containers:
  - name: spark-dev
    image: ghcr.io/ucsd-ets/spark-notebook:latest
    command: ["/bin/bash","-c"]
    args: ["jupyter notebook --ip 0.0.0.0 --port 8888 --allow-root"]
    ports:
    - containerPort: 8082
    - containerPort: 30007
    - containerPort: 40007
    - containerPort: 50007
    - containerPort: 60007
    - containerPort: 60008
    - containerPort: 60009
---
kind: Service
apiVersion: v1
metadata:
  name: spark-jupyter
  labels:
    # component: spark-dev
    app: spark-jupyter
spec:
  ports:
    - name: webui
      port: 8082
      targetPort: 8082
    - name: workerport
      port: 30007
      targetPort: 30007
    - name: executorport
      port: 40007
      targetPort: 40007
    - name: blockmgr
      port: 50007
      targetPort: 50007
    - name: fileserverport
      port: 60007
      targetPort: 60007
    - name: broadcastport
      port: 60008
      targetPort: 60008
    - name: replicaport
      port: 60009
      targetPort: 60009
  selector:
    app: spark-jupyter
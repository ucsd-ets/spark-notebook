# 1 master pod, 1 worker

# goal is to figure out how to get spark to run as master in the master pod and get spark to run as worker on worker pod and have them network together


### Definition for spark master and its service ###
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-main
  labels:
    app: spark-main
spec:
  replicas: 1
  selector:
    matchLabels:
      run: spark-main
  template:
    metadata:
      labels:
        run: spark-main
    spec:
      containers:
      - name: spark-main
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        command: ["/bin/sh","-c"]
        args: ["./spark-3.3.0-bin-hadoop3/sbin/start-master.sh; sleep inf"]
        ports:
        - containerPort: 7077
        - containerPort: 8080
        - containerPort: 4040
        - containerPort: 20002
        - containerPort: 50002
        - containerPort: 60002
        - containerPort: 60003
        - containerPort: 60004
---
apiVersion: v1
kind: Service
metadata:
  name: spark-main
  labels: 
    run: spark-main
spec:
  ports:
    - name: webui
      port: 8080
      targetPort: 8080
    - name: spark
      port: 7077
      targetPort: 7077
    - name: sparkui
      port: 4040
      targetPort: 4040
    - name: driverport
      port: 20002
      targetPort: 20002
    - name: blockmgrport
      port: 50002
      targetPort: 50002
    - name: fileserverport
      port: 60002
      targetPort: 60002
    - name: broadcastport
      port: 60003
      targetPort: 60003
    - name: replicaport
      port: 60004
      targetPort: 60004
  selector:
    run: spark-main
---
### Definition for spark worker and its service ###
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-dev
  labels:
    app: spark-dev
spec:
  replicas: 2
  selector:
    matchLabels:
      run: spark-dev
  template:
    metadata:
      labels:
        run: spark-dev
    spec:
      containers:
      - name: spark-dev
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        command: ["/bin/sh","-c"]
        args: ["./spark-3.3.0-bin-hadoop3/sbin/start-worker.sh spark://spark-main:7077; sleep inf"]
        ports:
        - containerPort: 8081
        - containerPort: 30002
        - containerPort: 40002
        - containerPort: 50002
        - containerPort: 60002
        - containerPort: 60003
        - containerPort: 60004
      initContainers:
      - name: init-checker
        image: ghcr.io/ucsd-ets/spark-notebook:latest
        command: [/opt/ping-check.sh"]
---
kind: Service
apiVersion: v1
metadata:
  name: spark-dev
  labels:
    # component: spark-dev
    run: spark-dev
spec:
  ports:
    - name: webui
      port: 8081
      targetPort: 8081
    - name: workerport
      port: 30002
      targetPort: 30002
    - name: executorport
      port: 40002
      targetPort: 40002
    - name: blockmgr
      port: 50002
      targetPort: 50002
    - name: fileserverport
      port: 60002
      targetPort: 60002
    - name: broadcastport
      port: 60003
      targetPort: 60003
    - name: replicaport
      port: 60004
      targetPort: 60004
  selector:
    run: spark-dev